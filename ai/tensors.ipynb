{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "## Two definitions\n",
    "\n",
    "Tensors have both a (strict) mathematical definition and a (loose) machine learning definition.\n",
    "\n",
    "I have heard it said that because ML is a child of many disciplines it takes words from all of them. Those disciplines often have different words for the same concepts so ML inherits that messiness.\n",
    "\n",
    "### Physics definition\n",
    "\n",
    "> A rank-n tensor in m-dimensions is a mathematical object that has n indices\n",
    "> and $m^n$ components and obeys certain transformation rules.\n",
    "\n",
    "Mathematically vectors & matrices and tensors are not the same thing but I think from ML point of view they basically are other names for rank 0, 1, 2 tensors.\n",
    "\n",
    "- The thing that makes a tensor a tensor is how it transforms.\n",
    "- a tensor is a number or collection of numbers which **maintains its meaning under transformations**\n",
    "- Physics seems to mostly deal with 3D (xyz) and 4D (xyz + time) tensors\n",
    "\n",
    "Velocity is a rank-1 tensor describing the motion of an object. The **meaning** of this tensor does not change even if you move the coordinate system around. The numbers in the tensor do change but the meaning does not.\n",
    "\n",
    "Aside: angular momentum is a pseudovector not a real vector because it cares about where you put your coordinate system - it works if your coordinate system 0 is at the centre of the rotation but doesn't make sense if you put it elsewhere\n",
    "\n",
    "If a real vector is zero in one set of coordinates it must be 0 in all of them - no exceptions.\n",
    "\n",
    "#### rank\n",
    "\n",
    "- Rank is the amount of info you need to find a single component within the tensor.\n",
    "- A 4x4 matrix is rank=2 because you only need an x and y to index a given component but shape = `[4,4]`\n",
    "- matrix notation is just a crutch to make you more comfy when learning about tensors\n",
    "- matrices are a convenient way to display any rank-2 tensor\n",
    "  - rank-0 => you need 0 index information to find a component\n",
    "  - rank-1 => you need 1 index information to find a component\n",
    "- Traditionally latin letters used for rank 2 and 3 dimensions (e.g. $T_{ij}$) and greek letters used for rank for 4 dimensions (e.g. $T_{\\alpha\\beta}$ or $T_{\\alpha\\beta\\mu}$). This allows you to guess at the dimensions without seeing them explicitly stated.\n",
    "\n",
    "### Machine learning\n",
    "\n",
    "- A ML generalisation of vectors and matrices to any number of dimensions\n",
    "- think of tensors as nested groups rather than trying to visualise as coordinates - it helps make sense of higher dimensions\n",
    "- primary data structure used in neural networks\n",
    "- Rank matters but when defining tensors you'll use dimensions\n",
    "- tensor = math generalisation of these concepts:\n",
    "  - comp-sci words\n",
    "    - number (0 indexes required)\n",
    "    - array (1 indexes required)\n",
    "    - 2d-array (2 indexes required)\n",
    "    - nd-array (n indexes required)\n",
    "  - math words\n",
    "    - scalar (0 indexes required)\n",
    "    - vector (1 indexes required)\n",
    "    - matrix (2 indexes required)\n",
    "    - nd-tensor (n indexes required)\n",
    "\n",
    "The n tells us how many indexes we need to index a specific element\n",
    "\n",
    "```bash\n",
    "# 500x500 image with 3 channels (RGB)\n",
    "(500,500,3) # rank 3 tensor (3 numbers required to find an element)\n",
    "\n",
    "# a simple video with 10 frames, each frame being one of the above images\n",
    "(10,500,500,3) # rank 4 tensor\n",
    "\n",
    "# a collection of 34 such videos\n",
    "(34,10,500,500,3) # rank 5 tensor\n",
    "```\n",
    "\n",
    "- Rank is number of axes (aka dimensions) present in the tensor\n",
    "- Each axis has a length with is the number of elements the tensor has along that axis\n",
    "- Axes make visual sense up to rank 3 but you have to give up visualising beyond that.\n",
    "- An axis is a dimension (two words for same thing)\n",
    "- The length of the axis tells us how many elements are along each axis\n",
    "- The shape of a tensor is the size of tensor and is expressed as an array e.g. `[3, 3]` is the size of a 3x3\n",
    "- Tensor **shape** is also called tensor **size** (pytorch calls it size and has a `torch.Size()` type to hold it.\n",
    "\n",
    "The rank is the length of the shape\n",
    "\n",
    "ML uses a convention to use $X$ to refer to the \"design matrix\" and assume the structure\n",
    "\n",
    "$$X \\in \\mathbb{R}^{n\\times m}$$\n",
    "\n",
    "where\n",
    "\n",
    "* n = number of training examples\n",
    "* m = number of features\n",
    "\n",
    "In the notation of each element, the subscript is the feature index and the superscript is the training example index\n",
    "\n",
    "In example of N traing images, each with 3 channels\n",
    "\n",
    "We typically use the convention: NCHW\n",
    "\n",
    "N = num training examples\n",
    "C = num color channels\n",
    "H = image height\n",
    "W = image width\n",
    "\n",
    "CHW = a feature\n",
    "\n",
    "?? Why is color first not last?\n",
    "\n",
    "## Tensors in pytorch\n",
    "\n",
    "- Tensors are immutable. You have to re-assign the tensor to get a new copy\n",
    "- Presumably under the hood the library tries to be as memory efficient as possible\n",
    "\n",
    "?? can you mix and match tensors stored in CPU memory and GPU memory in a single model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "example_array = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "t = torch.tensor(example_array)\n",
    "t"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have a shape which is an array giving the length of each axis of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the shape of the tensor\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tensor has rank 2 which we derived from the length of its shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_rank = len(t.shape)\n",
    "print(f\"This tensor has rank {derived_rank} which we derived from the length of its shape\")\n",
    "\n",
    "# you can also use ndim to get this\n",
    "len(t.shape) == t.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t.reshape(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t.reshape(1,9).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_t = t.reshape(1,9)\n",
    "t.reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch.LongTensor', 'torch.FloatTensor']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. creates a float vs an int in python\n",
    "\n",
    "t1 = torch.tensor([1,3,5])\n",
    "t2 = torch.tensor([1.,3.,5.])\n",
    "\n",
    "[t1.type(), t2.type()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0385e-02, 6.3443e-01, 1.9392e-01, 8.0916e-01, 1.5694e-01],\n",
       "         [6.8071e-01, 6.7303e-01, 1.0751e-01, 3.5412e-02, 6.3112e-01],\n",
       "         [3.9185e-01, 7.2436e-01, 6.6475e-01, 5.6696e-01, 9.3499e-01],\n",
       "         [1.3914e-01, 7.4445e-01, 6.2362e-01, 5.0541e-03, 8.9574e-01]],\n",
       "\n",
       "        [[6.9122e-02, 6.6526e-01, 4.5589e-02, 2.8011e-01, 3.7344e-01],\n",
       "         [5.3301e-01, 5.4943e-01, 4.2847e-01, 7.7138e-01, 4.9886e-01],\n",
       "         [9.6639e-01, 8.8726e-01, 8.9064e-01, 6.4565e-01, 5.6689e-01],\n",
       "         [9.3325e-01, 5.6758e-01, 6.8728e-01, 7.7214e-01, 3.8831e-01]],\n",
       "\n",
       "        [[5.2126e-01, 8.4500e-01, 1.1187e-01, 8.9798e-01, 5.4011e-01],\n",
       "         [3.6881e-01, 2.7149e-01, 3.1362e-01, 3.0655e-01, 6.8758e-01],\n",
       "         [2.1923e-01, 8.7920e-01, 3.0118e-04, 5.5278e-01, 9.7220e-02],\n",
       "         [7.9041e-02, 2.4013e-01, 6.0609e-01, 1.9326e-01, 8.9706e-02]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.rand(3,4,5, dtype=torch.float32)\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get num elements in a tensor\n",
    "t3.numel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape\n",
    "We can reshape the tensor to any other size where the number of elements is the same.\n",
    "\n",
    "You can get this by multiplying all the dimensions e.g.  3 * 4 * 5 = 60\n",
    "\n",
    "`reshape` can take a `-1` argument which tells it to use the dimension of the input tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0385e-02, 6.3443e-01, 1.9392e-01, 8.0916e-01, 1.5694e-01],\n",
       "         [6.8071e-01, 6.7303e-01, 1.0751e-01, 3.5412e-02, 6.3112e-01],\n",
       "         [3.9185e-01, 7.2436e-01, 6.6475e-01, 5.6696e-01, 9.3499e-01]],\n",
       "\n",
       "        [[1.3914e-01, 7.4445e-01, 6.2362e-01, 5.0541e-03, 8.9574e-01],\n",
       "         [6.9122e-02, 6.6526e-01, 4.5589e-02, 2.8011e-01, 3.7344e-01],\n",
       "         [5.3301e-01, 5.4943e-01, 4.2847e-01, 7.7138e-01, 4.9886e-01]],\n",
       "\n",
       "        [[9.6639e-01, 8.8726e-01, 8.9064e-01, 6.4565e-01, 5.6689e-01],\n",
       "         [9.3325e-01, 5.6758e-01, 6.8728e-01, 7.7214e-01, 3.8831e-01],\n",
       "         [5.2126e-01, 8.4500e-01, 1.1187e-01, 8.9798e-01, 5.4011e-01]],\n",
       "\n",
       "        [[3.6881e-01, 2.7149e-01, 3.1362e-01, 3.0655e-01, 6.8758e-01],\n",
       "         [2.1923e-01, 8.7920e-01, 3.0118e-04, 5.5278e-01, 9.7220e-02],\n",
       "         [7.9041e-02, 2.4013e-01, 6.0609e-01, 1.9326e-01, 8.9706e-02]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t3.reshape(6,10)\n",
    "t3.reshape(60, 1)\n",
    "t3.reshape(1, 60)\n",
    "t3.reshape(5, 2, 6)\n",
    "t3.reshape(3,4,5)\n",
    "t3.reshape(4,3,-1) # note the magical -1 arg meaning \"use input tensor's dimension\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze\n",
    "\n",
    "Squeezing a tensor removes all dimensions that have a length of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0385e-02, 6.3443e-01, 1.9392e-01, 8.0916e-01, 1.5694e-01, 6.8071e-01,\n",
       "        6.7303e-01, 1.0751e-01, 3.5412e-02, 6.3112e-01, 3.9185e-01, 7.2436e-01,\n",
       "        6.6475e-01, 5.6696e-01, 9.3499e-01, 1.3914e-01, 7.4445e-01, 6.2362e-01,\n",
       "        5.0541e-03, 8.9574e-01, 6.9122e-02, 6.6526e-01, 4.5589e-02, 2.8011e-01,\n",
       "        3.7344e-01, 5.3301e-01, 5.4943e-01, 4.2847e-01, 7.7138e-01, 4.9886e-01,\n",
       "        9.6639e-01, 8.8726e-01, 8.9064e-01, 6.4565e-01, 5.6689e-01, 9.3325e-01,\n",
       "        5.6758e-01, 6.8728e-01, 7.7214e-01, 3.8831e-01, 5.2126e-01, 8.4500e-01,\n",
       "        1.1187e-01, 8.9798e-01, 5.4011e-01, 3.6881e-01, 2.7149e-01, 3.1362e-01,\n",
       "        3.0655e-01, 6.8758e-01, 2.1923e-01, 8.7920e-01, 3.0118e-04, 5.5278e-01,\n",
       "        9.7220e-02, 7.9041e-02, 2.4013e-01, 6.0609e-01, 1.9326e-01, 8.9706e-02])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.reshape(1,60).squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsqueeze\n",
    "\n",
    "Unsqueezing a tensor adds a dimension with a length of 1. It takes a `dim` argument which ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0385e-02, 6.3443e-01, 1.9392e-01, 8.0916e-01, 1.5694e-01,\n",
       "          6.8071e-01, 6.7303e-01, 1.0751e-01, 3.5412e-02, 6.3112e-01,\n",
       "          3.9185e-01, 7.2436e-01, 6.6475e-01, 5.6696e-01, 9.3499e-01,\n",
       "          1.3914e-01, 7.4445e-01, 6.2362e-01, 5.0541e-03, 8.9574e-01,\n",
       "          6.9122e-02, 6.6526e-01, 4.5589e-02, 2.8011e-01, 3.7344e-01,\n",
       "          5.3301e-01, 5.4943e-01, 4.2847e-01, 7.7138e-01, 4.9886e-01,\n",
       "          9.6639e-01, 8.8726e-01, 8.9064e-01, 6.4565e-01, 5.6689e-01,\n",
       "          9.3325e-01, 5.6758e-01, 6.8728e-01, 7.7214e-01, 3.8831e-01,\n",
       "          5.2126e-01, 8.4500e-01, 1.1187e-01, 8.9798e-01, 5.4011e-01,\n",
       "          3.6881e-01, 2.7149e-01, 3.1362e-01, 3.0655e-01, 6.8758e-01,\n",
       "          2.1923e-01, 8.7920e-01, 3.0118e-04, 5.5278e-01, 9.7220e-02,\n",
       "          7.9041e-02, 2.4013e-01, 6.0609e-01, 1.9326e-01, 8.9706e-02]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.reshape(1,60).unsqueeze(dim=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten\n",
    "\n",
    "Flatten the tensor to a 1d array that contains all the scalar components of .\n",
    "\n",
    "Common in a CNN when you connect a convolutional layer to a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    t = t.reshape(1, -1)\n",
    "    t = t.squeeze()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.int64\n",
      "\n",
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([1,2,3])\n",
    "\n",
    "# IMPORTANT:\n",
    "# uses default dtype of torch.float32 no matter the type of the data\n",
    "# this one will make copy of the argument data\n",
    "made_by_class_constructor = torch.Tensor(data)  \n",
    "\n",
    "# all these factory functions have better docs and more configurable than constructor\n",
    "# they also infer the dtype from the data\n",
    "# this one will make copy of the argument data\n",
    "made_by_tensor = torch.tensor(data) \n",
    "\n",
    "# these factory functions will share data with `data` so you can move between\n",
    "# numpy array and pytorch tensors without array copying but be careful!\n",
    "\n",
    "# as_tensor will accept data structures other than a numpy array unlike from_numpy which is sticter\n",
    "made_by_as_tensor = torch.as_tensor(data) \n",
    "made_by_from_numpy = torch.from_numpy(data) \n",
    "\n",
    "print(torch.get_default_dtype())\n",
    "print(made_by_class_constructor.dtype)\n",
    "print(\"\")\n",
    "print(made_by_tensor.dtype)\n",
    "print(made_by_as_tensor.dtype)\n",
    "print(made_by_from_numpy.dtype)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# tensor factory func infers dtype from the incoming data\n",
    "assert torch.tensor(np.array([1.,2.,3.])).dtype == torch.float64, \"Unexpected dtype\"\n",
    "print(torch.tensor(np.array([1.,2.,3.]), dtype=torch.int32).dtype)\n",
    "\n",
    "\n",
    "# recommendation is to use tensor.tensor() as a default\n",
    "# use tensor.as_tensor() if you explicitly want data sharing (it's more flexibly than tensor.from_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
